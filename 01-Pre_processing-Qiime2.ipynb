{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "naughty-sewing",
   "metadata": {},
   "source": [
    "# 01: Pre-processing data with Qiime2\n",
    "\n",
    "This notebook takes the combined data outputs from Qiita (metadata, taxonomy, and ASV biome files) and splits them into genus-level biome tables for downstream analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "spiritual-episode",
   "metadata": {},
   "outputs": [],
   "source": [
    "from biom import Table\n",
    "from biom.util import biom_open\n",
    "from skbio import DistanceMatrix\n",
    "from os.path import abspath, join\n",
    "from qiime2 import Artifact\n",
    "from os import makedirs\n",
    "from qiime2.plugins import diversity\n",
    "from qiime2.plugins.feature_table.methods import filter_samples\n",
    "from qiime2 import Metadata\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "turned-amateur",
   "metadata": {},
   "source": [
    "### Data filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "primary-variety",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get biom qza\n",
    "\n",
    "biom_fp = './data/primate_micro_filtered_rarefied_table.qza' \n",
    "\n",
    "\n",
    "# get taxonomy qza\n",
    "\n",
    "tax_fp = './data/taxonomy_assignment_primate_micro_rarefied.qza'\n",
    "\n",
    "\n",
    "# get metadata\n",
    "\n",
    "md_fp = './data/primate_micro_filtered_metadata.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "roman-consortium",
   "metadata": {},
   "source": [
    "### Read in data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latest-running",
   "metadata": {},
   "source": [
    "#### Biom table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "incoming-currency",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read biom qza into qiime2 Artifact class\n",
    "\n",
    "biom_art = Artifact.load(abspath(biom_fp))\n",
    "\n",
    "# load the qiime2 artifact into biom Table class\n",
    "\n",
    "biom = biom_art.view(Table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alert-defensive",
   "metadata": {},
   "source": [
    "#### Taxonomy table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "floral-integration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read biom tax into qiime2 Artifact class\n",
    "\n",
    "tax_art = Artifact.load(abspath(tax_fp))\n",
    "\n",
    "# read taxonomy artifact as Pandas DF\n",
    "\n",
    "tax_df = tax_art.view(pd.DataFrame)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inappropriate-visitor",
   "metadata": {},
   "source": [
    "#### Metadata file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "subjective-latest",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in metadata\n",
    "\n",
    "metadata = Metadata.load(md_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infrared-shooting",
   "metadata": {},
   "source": [
    "### Write separate Biom tables per genus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "international-medication",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group all the code into a single method to facilitate rerunning\n",
    "\n",
    "def split_otu_tables_by_tax(biom_t, tax_df, output_dir,\n",
    "                            metadata,\n",
    "                            threshold=5,\n",
    "                            level=5,\n",
    "                            tax_names=['Kingdom',\n",
    "                                       'Phylum',\n",
    "                                       'Class',\n",
    "                                       'Order',\n",
    "                                       'Family', \n",
    "                                       'Genus',\n",
    "                                       'Species'],\n",
    "                            sampling_depth=5,\n",
    "                            export_viz=False):\n",
    "    # fix the taxonomy\n",
    "    tax_cols = tax_df['Taxon'].str.split('; ', expand=True)\n",
    "\n",
    "    tax_cols.columns = tax_names\n",
    "    \n",
    "    # make concatenated tax string at appropriate level\n",
    "    cat_cols = tax_names[:level+1]\n",
    "    print(cat_cols)\n",
    "    tax_str = tax_cols[cat_cols].fillna(' ').apply(lambda x: '; '.join(x), axis=1)\n",
    "    \n",
    "    # find taxa above threshold number of OTUs\n",
    "    tax_thr = pd.Series(tax_str.value_counts()).where(lambda x : x >= threshold).dropna().index\n",
    "    \n",
    "    # make output dir\n",
    "    makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # for each tax_thr value, filter the OTU table and write to file\n",
    "    \n",
    "    # also, make a dict of all filtered tables and keep in memory for downstream analysis\n",
    "    tax_arts = {}\n",
    "    \n",
    "    for t in tax_thr:\n",
    "        t_ids =  pd.Series(tax_str).where(lambda x : x == t).dropna().index\n",
    "        tax_otu = biom_t.filter(t_ids, axis='observation', inplace=False)\n",
    "        tax_otu.remove_empty(inplace=True)\n",
    "        \n",
    "        \n",
    "        output_f = t.replace(';','_').replace(' ','')\n",
    "        output_fn = '{0}.{1}.qza'.format(tax_names[level], output_f)\n",
    "        output_fp = join(output_dir, output_fn)\n",
    "\n",
    "        # export as q2 artifact\n",
    "        tax_art = Artifact.import_data(\"FeatureTable[Frequency]\", tax_otu)\n",
    "        tax_art.save(output_fp)\n",
    "        \n",
    "        tax_arts[t] = tax_art\n",
    "        \n",
    "        if export_viz:\n",
    "            # export the bc and jaccard emperor viz\n",
    "            (rarefied_table,\n",
    "             observed_otus_vector,\n",
    "             shannon_vector,\n",
    "             evenness_vector,\n",
    "             jaccard_distance_matrix,\n",
    "             bray_curtis_distance_matrix,\n",
    "             jaccard_pcoa_results,\n",
    "             bray_curtis_pcoa_results,\n",
    "             jaccard_emperor,\n",
    "             bray_curtis_emperor) = diversity.pipelines.core_metrics(table=tax_art, \n",
    "                                                                    sampling_depth=sampling_depth,\n",
    "                                                                    metadata=metadata)\n",
    "\n",
    "            jaccard_fp = join(output_dir, '{0}.{1}.emperor.jaccard.qzv'.format(tax_names[level], output_f))\n",
    "            bc_fp = join(output_dir, '{0}.{1}.emperor.braycurtis.qzv'.format(tax_names[level], output_f))\n",
    "            jaccard_emperor.save(jaccard_fp)\n",
    "            bray_curtis_emperor.save(bc_fp)\n",
    "\n",
    "    return(tax_arts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "electric-extent",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = './output/genus_asv_tables'\n",
    "\n",
    "makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "prime-harrison",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Kingdom', 'Phylum', 'Class', 'Order', 'Family', 'Genus']\n"
     ]
    }
   ],
   "source": [
    "genus_tables = split_otu_tables_by_tax(biom,\n",
    "                                       tax_df,\n",
    "                                       output_dir,\n",
    "                                       metadata,\n",
    "                                       level=5,\n",
    "                                       threshold=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dangerous-amino",
   "metadata": {},
   "source": [
    "## Calculate Sorensen-Dice beta diversity and Host Specificity metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "related-shipping",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jgs286/miniconda3/envs/houtz2021/lib/python3.6/site-packages/sklearn/metrics/pairwise.py:1761: DataConversionWarning: Data was converted to boolean for metric dice\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/jgs286/miniconda3/envs/houtz2021/lib/python3.6/site-packages/sklearn/metrics/pairwise.py:1761: DataConversionWarning: Data was converted to boolean for metric dice\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/jgs286/miniconda3/envs/houtz2021/lib/python3.6/site-packages/sklearn/metrics/pairwise.py:1761: DataConversionWarning: Data was converted to boolean for metric dice\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/jgs286/miniconda3/envs/houtz2021/lib/python3.6/site-packages/sklearn/metrics/pairwise.py:1761: DataConversionWarning: Data was converted to boolean for metric dice\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/jgs286/miniconda3/envs/houtz2021/lib/python3.6/site-packages/sklearn/metrics/pairwise.py:1761: DataConversionWarning: Data was converted to boolean for metric dice\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/jgs286/miniconda3/envs/houtz2021/lib/python3.6/site-packages/sklearn/metrics/pairwise.py:1761: DataConversionWarning: Data was converted to boolean for metric dice\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/jgs286/miniconda3/envs/houtz2021/lib/python3.6/site-packages/sklearn/metrics/pairwise.py:1761: DataConversionWarning: Data was converted to boolean for metric dice\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "metric = 'dice'\n",
    "distance_dir = 'output/distance'\n",
    "metadata_col = 'species_geo_captivity'\n",
    "makedirs(distance_dir, exist_ok=True)\n",
    "\n",
    "for genus in genus_tables:\n",
    "    tax_dir = join(distance_dir,\n",
    "                   genus.replace(';','_').replace(' ',''))\n",
    "    makedirs(tax_dir, exist_ok=True)\n",
    "    \n",
    "    # filter empty samples\n",
    "    genus_filtered = filter_samples(genus_tables[genus],\n",
    "                                    min_frequency=1)\n",
    "    \n",
    "    # get distance matrix\n",
    "    dm = diversity.actions.beta(genus_filtered.filtered_table,\n",
    "                            metric)\n",
    "    \n",
    "    # write distance matrix to file \n",
    "    dm.distance_matrix.view(DistanceMatrix).to_series().to_csv(join(tax_dir,\n",
    "                                                                    'distance_list.dice.tsv'),\n",
    "                                                               sep='\\t')\n",
    "    \n",
    "    # calculate beta group significance\n",
    "    bgs = diversity.actions.beta_group_significance(dm.distance_matrix,\n",
    "                                                    metadata.get_column(metadata_col),\n",
    "                                                    pairwise=True,\n",
    "                                                    method='permanova')\n",
    "    \n",
    "    # write results to directory\n",
    "    bgs.visualization.export_data(join(tax_dir,'permanova'))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
